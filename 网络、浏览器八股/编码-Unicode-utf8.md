字符在计算机中使用二进制存储。

标准`ASCII`码采用`7`位二进制数，剩下的首位二进制为0，比如：常见的大写字母A的十进制数为65。

由于ASCII只有8位二进制数，最多表示256个字符，不够使用，所以推出了可以囊括所有字符的字符集`Unicode`。

Unicode为每一个字符对应一个码点，范围是`U+000`~`U+10FFF`，U+表示这是Unicode字符集，后面跟着一个十六进制数。

而`UTF-8`、`UTF-16`等是针对Unicode码点的编码规则：将码点转换为字节序列（能被机器识别的语言）的编码规则

比如最常见的`UTF-8`编码规则：

**变长字节编码方式**

| Unicode符号范围「十六进制」 | UTF-8编码「二进制」        |
| --------------------------- | -------------------------- |
| 0000 0000-0000 007F         | 0xxxxxxxx                  |
| 0000 0080-0000 07FF         | 110xxxxx 10xxxxxx          |
| 0000 0800-0000 FFFF         | 1110xxxx 10xxxxxx 10xxxxxx |
| 0001 0000-0010 FFFF         | 11110xxx 10xxxxxx 10xxxxxx |

+ 单字节字符（8位二进制）：占用一个字节单位，首位为0，后面7位代表Unicode中的序号
+ n字节字符（n*8位二进制）：第一个字节的前n为为1，第n+1位为0；后面字节的前两位为10，剩下没有提及的二进制位为这个符号的Unicode码